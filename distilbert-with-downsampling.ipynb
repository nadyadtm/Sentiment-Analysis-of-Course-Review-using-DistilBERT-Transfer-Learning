{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Sentiment Analysis in Course Review using DistilBERT Transfer Learning\n\n## Background\nDalam perusahaan edukasi, feedback siswa merupakan komponen penting dalam meningkatkan kualitas pembelajaran. Biasanya, feedback tersebut dalam bentuk tulisan atau teks. Feedback teks mengandung berbagai macam insight sehingga dapat dieksplorasi lebih lanjut.\n\nDalam data bentuk teks, kita dapat menemukan sentimen dari teks tersebut, yaitu mengetahui apakah feedback tersebut bersifat positif, netral, atau negatif. Namun, bila jumlah feedback besar akan sangat sulit untuk mengecek satu-satu sentimennya. Oleh karena itu perlu proses yang otomatis untuk mendapatkan sentimen dari teks tersebut, yaitu dengan menggunakan analisis sentimen.","metadata":{"id":"-6ETzS8O1wjN"}},{"cell_type":"markdown","source":"## Install Package","metadata":{"id":"d8E-9Ry1_RIf"}},{"cell_type":"code","source":"# !pip install nlpaug","metadata":{"id":"9vO_aOkO_UKM","execution":{"iopub.status.busy":"2023-05-17T01:52:13.230630Z","iopub.execute_input":"2023-05-17T01:52:13.231332Z","iopub.status.idle":"2023-05-17T01:52:13.239099Z","shell.execute_reply.started":"2023-05-17T01:52:13.231279Z","shell.execute_reply":"2023-05-17T01:52:13.238093Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install transformers","metadata":{"id":"JYu9o-_DEq03","outputId":"9a91f33d-6b75-4f69-ba4c-afb226128183","execution":{"iopub.status.busy":"2023-05-17T01:52:13.245043Z","iopub.execute_input":"2023-05-17T01:52:13.245793Z","iopub.status.idle":"2023-05-17T01:52:28.204395Z","shell.execute_reply.started":"2023-05-17T01:52:13.245763Z","shell.execute_reply":"2023-05-17T01:52:28.203062Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.28.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.28.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.11.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.64.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.3.23)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2022.12.7)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"## Set Device","metadata":{"id":"0DhkBxRhGEbS"}},{"cell_type":"code","source":"#mengecek apakah terdapat GPU pada komputer\nimport torch\nif torch.cuda.is_available():       \n    device = torch.device(\"cuda\")\n    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n    print('Device name:', torch.cuda.get_device_name(0))\n#jika tidak ada maka gunakan CPU untuk menjalankan program\nelse:\n    print('No GPU available, using the CPU instead.')\n    device = torch.device(\"cpu\")","metadata":{"id":"5FBnzkWXGGZh","outputId":"25e9734f-05e8-41ad-ee8d-c44af01efadd","execution":{"iopub.status.busy":"2023-05-17T01:52:28.208044Z","iopub.execute_input":"2023-05-17T01:52:28.208622Z","iopub.status.idle":"2023-05-17T01:52:32.025791Z","shell.execute_reply.started":"2023-05-17T01:52:28.208583Z","shell.execute_reply":"2023-05-17T01:52:32.024753Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"There are 2 GPU(s) available.\nDevice name: Tesla T4\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Import Packages","metadata":{"id":"Jcvi2xO61wjc"}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom os import path\nfrom PIL import Image\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nimport torch\nimport transformers\nfrom transformers import DistilBertModel, DistilBertTokenizer\nfrom torch.optim import AdamW\n\nimport os\nimport nltk\nnltk.download(\"punkt\")\n\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)\ntorch.manual_seed(RANDOM_SEED)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","id":"-G9LOlgv1wje","outputId":"17a123a8-aad8-4900-f7ac-4523a458a0df","execution":{"iopub.status.busy":"2023-05-17T01:52:32.032493Z","iopub.execute_input":"2023-05-17T01:52:32.033162Z","iopub.status.idle":"2023-05-17T01:52:43.708206Z","shell.execute_reply.started":"2023-05-17T01:52:32.033128Z","shell.execute_reply":"2023-05-17T01:52:43.707231Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7ec2c1bb6090>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Load Dataset\nDalam notebook ini, akan digunakan dataset 100k Courseras Course Review, yang telah discrapping dari website coursera.","metadata":{"id":"dNCbpA871wjm"}},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/100k-courseras-course-reviews-dataset/reviews.csv\")\ndf.head()","metadata":{"id":"1u1rs9QC1wjn","outputId":"153c1c37-ed1e-4cde-9bc2-1cf10baaff5f","execution":{"iopub.status.busy":"2023-05-17T01:52:43.711660Z","iopub.execute_input":"2023-05-17T01:52:43.711971Z","iopub.status.idle":"2023-05-17T01:52:44.161433Z","shell.execute_reply.started":"2023-05-17T01:52:43.711942Z","shell.execute_reply":"2023-05-17T01:52:44.160337Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"   Id                                             Review  Label\n0   0                               good and interesting      5\n1   1  This class is very helpful to me. Currently, I...      5\n2   2  like!Prof and TAs are helpful and the discussi...      5\n3   3  Easy to follow and includes a lot basic and im...      5\n4   4  Really nice teacher!I could got the point eazl...      4","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>Review</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>good and interesting</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>This class is very helpful to me. Currently, I...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>like!Prof and TAs are helpful and the discussi...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Easy to follow and includes a lot basic and im...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Really nice teacher!I could got the point eazl...</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# convert label start from 0\ndf['Label'] = df['Label'].astype(\"category\")\ndf['Label'] = df['Label'].cat.rename_categories(\n    {\n        5 : 4, 4 : 3, 3 : 2, 2: 1, 1: 0\n    }\n)","metadata":{"id":"dd6E4UtzQeA1","execution":{"iopub.status.busy":"2023-05-17T01:52:44.162883Z","iopub.execute_input":"2023-05-17T01:52:44.163351Z","iopub.status.idle":"2023-05-17T01:52:44.178588Z","shell.execute_reply.started":"2023-05-17T01:52:44.163293Z","shell.execute_reply":"2023-05-17T01:52:44.177752Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#downsampling rating 4 (3) and 5 (4)\ndf_1_3 = df[(df[\"Label\"]!=3) & (df[\"Label\"]!=4)]\ndf_4 = df[df[\"Label\"]==3]\ndf_5 = df[df[\"Label\"]==4]\n\nfrom sklearn.utils import resample\nrat4_downsample = resample(df_4,\n             replace=True,\n             n_samples=len(df_1_3[df_1_3[\"Label\"]==2]),\n             random_state=42)\n\nrat5_downsample = resample(df_5,\n             replace=True,\n             n_samples=len(df_1_3[df_1_3[\"Label\"]==2]),\n             random_state=42)\n\ndf = pd.concat([df_1_3,rat4_downsample,rat5_downsample])","metadata":{"execution":{"iopub.status.busy":"2023-05-17T01:52:44.180009Z","iopub.execute_input":"2023-05-17T01:52:44.180378Z","iopub.status.idle":"2023-05-17T01:52:44.207046Z","shell.execute_reply.started":"2023-05-17T01:52:44.180347Z","shell.execute_reply":"2023-05-17T01:52:44.206138Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"len(df)","metadata":{"id":"_jM3yUAbQ4kn","outputId":"47f03b27-8cbf-4c3e-e582-f34a18f97234","execution":{"iopub.status.busy":"2023-05-17T01:52:54.314378Z","iopub.execute_input":"2023-05-17T01:52:54.315262Z","iopub.status.idle":"2023-05-17T01:52:54.322624Z","shell.execute_reply.started":"2023-05-17T01:52:54.315229Z","shell.execute_reply":"2023-05-17T01:52:54.321534Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"19933"},"metadata":{}}]},{"cell_type":"markdown","source":"## Text Analysis (EDA)\nPada bagian ini, akan dilakukan EDA (Exploratory Data Analysis) untuk mendapatkan insight dari dataset tersebut.","metadata":{"id":"bzGhqtj81wjp"}},{"cell_type":"markdown","source":"### Class Distribution\nPada bagian ini, akan dilakukan pengecekan distribusi kelas dengan menghitung jumlah kalimat yang termasuk kelas tersebut","metadata":{"id":"TitMwOi11wjq"}},{"cell_type":"code","source":"# check class distribution\nimport seaborn as sns\ndf[\"Label\"].value_counts()","metadata":{"id":"XJKg6FSn1wjs","outputId":"56fde5fb-d8f7-4aad-df5a-e12d97459883","execution":{"iopub.status.busy":"2023-05-17T01:52:58.956043Z","iopub.execute_input":"2023-05-17T01:52:58.956451Z","iopub.status.idle":"2023-05-17T01:52:58.968705Z","shell.execute_reply.started":"2023-05-17T01:52:58.956420Z","shell.execute_reply":"2023-05-17T01:52:58.967798Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"2    5071\n3    5071\n4    5071\n0    2469\n1    2251\nName: Label, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"### Checking Sentence Length\nPada bagian ini, akan dilakukan pengecekan panjang kalimat dengan menghitung jumlah kata per kalimat.","metadata":{"id":"4ho6TpFx1wju"}},{"cell_type":"code","source":"# check len sentence\nfrom nltk.tokenize import word_tokenize\n\ndf['length_sen'] = df['Review'].apply(lambda x : len(word_tokenize(x)))","metadata":{"id":"LFTqwtur1wjy","execution":{"iopub.status.busy":"2023-05-17T01:53:01.678049Z","iopub.execute_input":"2023-05-17T01:53:01.681477Z","iopub.status.idle":"2023-05-17T01:53:11.651728Z","shell.execute_reply.started":"2023-05-17T01:53:01.681440Z","shell.execute_reply":"2023-05-17T01:53:11.650724Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"id":"L1hCEPiE1wj0","outputId":"29f8da39-e266-458f-96a0-ff50d67b710c","execution":{"iopub.status.busy":"2023-05-17T01:53:11.653605Z","iopub.execute_input":"2023-05-17T01:53:11.653951Z","iopub.status.idle":"2023-05-17T01:53:11.668119Z","shell.execute_reply.started":"2023-05-17T01:53:11.653920Z","shell.execute_reply":"2023-05-17T01:53:11.667019Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"    Id                                             Review Label  length_sen\n7    7  I was disappointed because the name is mislead...     2          69\n13  13  Good content, but the course setting does (at ...     2          27\n17  17  This course does not say anything about digiti...     1          18\n19  19  The course content is quite good, though it co...     2          32\n48  48  I'll start by saying that this course gives a ...     2         122","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>Review</th>\n      <th>Label</th>\n      <th>length_sen</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>I was disappointed because the name is mislead...</td>\n      <td>2</td>\n      <td>69</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>13</td>\n      <td>Good content, but the course setting does (at ...</td>\n      <td>2</td>\n      <td>27</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>17</td>\n      <td>This course does not say anything about digiti...</td>\n      <td>1</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>19</td>\n      <td>The course content is quite good, though it co...</td>\n      <td>2</td>\n      <td>32</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>48</td>\n      <td>I'll start by saying that this course gives a ...</td>\n      <td>2</td>\n      <td>122</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Berikut ini adalah maksimal panjang kalimat dari dataset tersebut.","metadata":{"id":"MQz9GOVZ1wj0"}},{"cell_type":"code","source":"# max length\nmax_len = max(df['length_sen'])\nprint(\"Max Length : \", max(df['length_sen']))","metadata":{"id":"76F7uKta1wj3","outputId":"932d0147-aee6-41eb-dc74-ee9ff7279e8f","execution":{"iopub.status.busy":"2023-05-17T01:53:11.669442Z","iopub.execute_input":"2023-05-17T01:53:11.670466Z","iopub.status.idle":"2023-05-17T01:53:11.684365Z","shell.execute_reply.started":"2023-05-17T01:53:11.670429Z","shell.execute_reply":"2023-05-17T01:53:11.683206Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Max Length :  1314\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Text Preprocessing","metadata":{"id":"lSkEHuOM1wj4"}},{"cell_type":"code","source":"# Lowercase\ndf['Review'] = df['Review'].apply(lambda x : str.lower(x))","metadata":{"id":"iKavCi4W1wj4","execution":{"iopub.status.busy":"2023-05-17T01:53:11.687581Z","iopub.execute_input":"2023-05-17T01:53:11.688715Z","iopub.status.idle":"2023-05-17T01:53:11.713797Z","shell.execute_reply.started":"2023-05-17T01:53:11.688670Z","shell.execute_reply":"2023-05-17T01:53:11.712681Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"### Data Splitting","metadata":{"id":"-7LPCo_F1wj9"}},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(df[\"Review\"], df[\"Label\"], test_size=0.2, random_state=42, stratify = df[\"Label\"])\nX_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42, stratify = y_test)","metadata":{"id":"BRH1THCv1wj9","execution":{"iopub.status.busy":"2023-05-17T01:53:11.715642Z","iopub.execute_input":"2023-05-17T01:53:11.716301Z","iopub.status.idle":"2023-05-17T01:53:11.742599Z","shell.execute_reply.started":"2023-05-17T01:53:11.716265Z","shell.execute_reply":"2023-05-17T01:53:11.741716Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"print(X_train.shape)\nprint(X_test.shape)\nprint(X_val.shape)","metadata":{"id":"5y5KBMQ1Ccfd","outputId":"fb838a4f-f2d6-4ce3-b159-aa1dfbfb76aa","execution":{"iopub.status.busy":"2023-05-17T01:53:11.743868Z","iopub.execute_input":"2023-05-17T01:53:11.744266Z","iopub.status.idle":"2023-05-17T01:53:11.751129Z","shell.execute_reply.started":"2023-05-17T01:53:11.744226Z","shell.execute_reply":"2023-05-17T01:53:11.749300Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"(15946,)\n(1994,)\n(1993,)\n","output_type":"stream"}]},{"cell_type":"code","source":"y_train.value_counts()","metadata":{"id":"t_knlgPGCiYN","outputId":"089e9250-f61d-4702-eaef-b4f4551793e9","execution":{"iopub.status.busy":"2023-05-17T01:53:11.753116Z","iopub.execute_input":"2023-05-17T01:53:11.753930Z","iopub.status.idle":"2023-05-17T01:53:11.764404Z","shell.execute_reply.started":"2023-05-17T01:53:11.753896Z","shell.execute_reply":"2023-05-17T01:53:11.763219Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"2    4057\n3    4057\n4    4056\n0    1975\n1    1801\nName: Label, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"y_test.value_counts()","metadata":{"id":"ag_vy_KdCnni","outputId":"375a83e9-d774-4aee-dac6-07b8bce4e80e","execution":{"iopub.status.busy":"2023-05-17T01:53:11.765999Z","iopub.execute_input":"2023-05-17T01:53:11.766562Z","iopub.status.idle":"2023-05-17T01:53:11.776021Z","shell.execute_reply.started":"2023-05-17T01:53:11.766527Z","shell.execute_reply":"2023-05-17T01:53:11.774749Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"4    508\n2    507\n3    507\n0    247\n1    225\nName: Label, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"y_val.value_counts()","metadata":{"id":"f-mWy4_iq_PU","outputId":"10b82713-a8f0-4cc4-f1f2-5fa9912706cf","execution":{"iopub.status.busy":"2023-05-17T01:53:11.777450Z","iopub.execute_input":"2023-05-17T01:53:11.778663Z","iopub.status.idle":"2023-05-17T01:53:11.787265Z","shell.execute_reply.started":"2023-05-17T01:53:11.778631Z","shell.execute_reply":"2023-05-17T01:53:11.786211Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"2    507\n3    507\n4    507\n0    247\n1    225\nName: Label, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"## Build BERT Model\n\n- Tambah penjelasan bert model --> dibaliknya apa, basic algoritma\n- penjelasan framework pytorch","metadata":{"id":"BgfXOVv3CXET"}},{"cell_type":"code","source":"#import bert tokenizer, pilih yang multilingual karena lebih dari 1 bahasa\n\ntokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-cased')\nmodel = DistilBertModel.from_pretrained('distilbert-base-cased')","metadata":{"id":"0DaRUDivCZIE","outputId":"92283809-5af4-4747-ad1e-3dc9fdd594fd","execution":{"iopub.status.busy":"2023-05-17T01:53:11.790648Z","iopub.execute_input":"2023-05-17T01:53:11.791668Z","iopub.status.idle":"2023-05-17T01:53:15.580485Z","shell.execute_reply.started":"2023-05-17T01:53:11.791631Z","shell.execute_reply":"2023-05-17T01:53:15.579555Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c2fc4be98164d8cb22aa5995b93c43d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94b9b1451edd42f8af2fbe8be3eae544"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/411 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60c00b2a39184f4089de68555c79a308"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/263M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c7d9a3e2866432a9e066bd8f56b71f5"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertModel: ['vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_projector.weight']\n- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### BERT Data Loader","metadata":{"id":"sbTPjLDvPjd1"}},{"cell_type":"code","source":"#fungsi untuk loading dataset\nfrom torch.utils.data import Dataset\n\nclass ReviewDataset(Dataset):\n  def __init__(self, reviews, labels, max_len, tokenizer):\n    self.reviews = reviews.reset_index()[\"Review\"]\n    self.labels = labels.reset_index()[\"Label\"]\n    self.max_len = max_len\n    self.tokenizer = tokenizer\n\n  def __len__(self):\n    return len(self.labels)\n  \n  def __getitem__(self, idx):\n    reviews = self.reviews[idx]\n    labels = self.labels[idx]\n\n    encoding = self.tokenizer.encode_plus(\n      reviews,                      \n      add_special_tokens=True,    \n      max_length=self.max_len,    \n      pad_to_max_length=True,     \n      truncation=True,            \n      return_attention_mask=True, \n      return_tensors='pt'         \n    )\n\n    return {\n        'review': reviews,\n        'input_ids': encoding['input_ids'].flatten(),\n        'attention_mask': encoding['attention_mask'].flatten(),\n        'label': torch.tensor(labels, dtype=torch.long)\n    }","metadata":{"id":"ux7wzfLvPea2","execution":{"iopub.status.busy":"2023-05-17T01:53:15.582682Z","iopub.execute_input":"2023-05-17T01:53:15.583051Z","iopub.status.idle":"2023-05-17T01:53:15.593263Z","shell.execute_reply.started":"2023-05-17T01:53:15.583016Z","shell.execute_reply":"2023-05-17T01:53:15.592105Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"train_data = ReviewDataset(X_train,y_train, 512, tokenizer)\nval_data = ReviewDataset(X_val,y_val, 512, tokenizer)\ntest_data = ReviewDataset(X_test,y_test, 512, tokenizer)","metadata":{"id":"iPYh8-7Cf65e","execution":{"iopub.status.busy":"2023-05-17T01:53:15.594921Z","iopub.execute_input":"2023-05-17T01:53:15.595460Z","iopub.status.idle":"2023-05-17T01:53:15.610184Z","shell.execute_reply.started":"2023-05-17T01:53:15.595424Z","shell.execute_reply":"2023-05-17T01:53:15.609174Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\ntrain_dataloader = DataLoader(train_data, batch_size=32, shuffle=True)\nval_dataloader = DataLoader(val_data, batch_size=32, shuffle=True)\ntest_dataloader = DataLoader(test_data, batch_size=32, shuffle=True)","metadata":{"id":"4HKtUo9Wh5TJ","execution":{"iopub.status.busy":"2023-05-17T01:53:15.612695Z","iopub.execute_input":"2023-05-17T01:53:15.613042Z","iopub.status.idle":"2023-05-17T01:53:15.621987Z","shell.execute_reply.started":"2023-05-17T01:53:15.613012Z","shell.execute_reply":"2023-05-17T01:53:15.620815Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"### Bert Transfer Learning","metadata":{"id":"gPhfd5ZNqQa3"}},{"cell_type":"code","source":"from torch import nn\nclass Bert_TL(nn.Module):\n  def __init__(self,bert):\n    super(Bert_TL, self).__init__()\n    self.bert = bert\n    self.fc1 = nn.Linear(768,512)\n    self.relu = nn.ReLU()\n    self.fc2 = nn.Linear(512,5)\n  \n  def forward(self, input_ids, attention_mask):\n    hidden = self.bert(input_ids = input_ids, attention_mask = attention_mask)\n    x = self.fc1(hidden[0][:, 0, :])\n    x = self.relu(x)\n    x = self.fc2(x)\n    \n    return x","metadata":{"id":"t3UaEB9wqZdb","execution":{"iopub.status.busy":"2023-05-17T01:53:15.623498Z","iopub.execute_input":"2023-05-17T01:53:15.623860Z","iopub.status.idle":"2023-05-17T01:53:15.634864Z","shell.execute_reply.started":"2023-05-17T01:53:15.623825Z","shell.execute_reply":"2023-05-17T01:53:15.634140Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"model = Bert_TL(model)\nmodel.to(torch.device(\"cuda\"))","metadata":{"id":"NMADSNPZq7s2","outputId":"05765314-5d78-4b8b-eb6f-8d4090505c69","execution":{"iopub.status.busy":"2023-05-17T01:53:16.469078Z","iopub.execute_input":"2023-05-17T01:53:16.469471Z","iopub.status.idle":"2023-05-17T01:53:22.430398Z","shell.execute_reply.started":"2023-05-17T01:53:16.469439Z","shell.execute_reply":"2023-05-17T01:53:22.429514Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"Bert_TL(\n  (bert): DistilBertModel(\n    (embeddings): Embeddings(\n      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (transformer): Transformer(\n      (layer): ModuleList(\n        (0-5): 6 x TransformerBlock(\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n            (activation): GELUActivation()\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n      )\n    )\n  )\n  (fc1): Linear(in_features=768, out_features=512, bias=True)\n  (relu): ReLU()\n  (fc2): Linear(in_features=512, out_features=5, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"# Inisiasi hyperparameter\nlearning_rate = 1e-3\n\n#inisiasi loss function\nloss_fn =nn.CrossEntropyLoss().to(device)\noptimizer = AdamW(model.parameters(), lr=learning_rate)\n\nfor param in model.bert.parameters():\n    param.requires_grad = False","metadata":{"id":"3dO0UEzmD5du","execution":{"iopub.status.busy":"2023-05-17T01:53:39.665543Z","iopub.execute_input":"2023-05-17T01:53:39.666015Z","iopub.status.idle":"2023-05-17T01:53:39.680304Z","shell.execute_reply.started":"2023-05-17T01:53:39.665974Z","shell.execute_reply":"2023-05-17T01:53:39.679351Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"def train_loop(\n  data_loader, \n  model, \n  loss_fn, \n  optimizer, \n  device, \n  n_examples\n):\n  #menandakan bahwa model sedang dilatih\n  model = model.train()\n\n  losses = []\n  correct_predictions = 0\n  \n  #iterasi di setiap data\n  for d in data_loader:\n\n    #mengambil input id, attention mask, dan target dari setiap data\n    input_ids = d[\"input_ids\"].to(device)\n    attention_mask = d[\"attention_mask\"].to(device)\n    targets = d[\"label\"].to(device)\n\n    #mengeluarkan output dari data tersebut\n    outputs = model(\n      input_ids=input_ids,\n      attention_mask=attention_mask\n    )\n\n    #mengeluarkan prediksi target\n    _, preds = torch.max(outputs, dim=1)\n\n    #mengeluarkan lossnya\n    loss = loss_fn(outputs, targets)\n\n    #menjumlahkan prediksi target yang benar\n    correct_predictions += torch.sum(preds == targets)\n\n    #mengumpulkan loss dari output dan target\n    losses.append(loss.item())\n\n    loss.backward()\n\n    #untuk menghindari vanishing gradient\n    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n    optimizer.step()\n    optimizer.zero_grad()\n\n  #mengembalikan akurasi dan rata-rata loss\n  return correct_predictions.double() / n_examples, np.mean(losses)\n\n\ndef test_loop(model, data_loader, loss_fn, device, n_examples):\n\n  #menandakan model sedang dievaluasi\n  model = model.eval()\n\n  #array losses dari setiap data dan variabel correct_prediction untuk jumlah prediksi benar\n  losses = []\n  correct_predictions = 0\n\n  with torch.no_grad():\n    for d in data_loader:\n      #mengambil input id, attention mask, dan target dari setiap data\n      input_ids = d[\"input_ids\"].to(device)\n      attention_mask = d[\"attention_mask\"].to(device)\n      targets = d[\"label\"].to(device)\n\n      #mengambil output dari data\n      outputs = model(\n        input_ids=input_ids,\n        attention_mask=attention_mask\n      )\n\n      #mengambil kelas prediksi\n      _, preds = torch.max(outputs, dim=1)\n      \n      #mengeluarkan loss dari output dan targets\n      loss = loss_fn(outputs, targets)\n\n      #menjumlahkan prediksi yang benar\n      correct_predictions += torch.sum(preds == targets)\n      losses.append(loss.item())\n\n  #mengembalikan akurasi dan rata-rata loss\n  return correct_predictions.double() / n_examples, np.mean(losses)","metadata":{"id":"nLDUnQI81ADw","execution":{"iopub.status.busy":"2023-05-17T01:53:40.942615Z","iopub.execute_input":"2023-05-17T01:53:40.943052Z","iopub.status.idle":"2023-05-17T01:53:40.964744Z","shell.execute_reply.started":"2023-05-17T01:53:40.943016Z","shell.execute_reply":"2023-05-17T01:53:40.963598Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# loss_fn = nn.CrossEntropyLoss()\n# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n\nepochs = 2\nfor t in range(epochs):\n    print(f\"Epoch {t+1}\\n-------------------------------\")\n    train_acc, train_loss = train_loop(train_dataloader, model, loss_fn, optimizer,device,len(X_train))\n    #memanggil fungsi eval model\n    val_acc, val_loss = test_loop(\n      model,\n      val_dataloader,\n      loss_fn, \n      device, \n      len(X_val)\n    )\n\n    #mencetak val loss dan accuracy\n    print(f'Train loss {train_loss} accuracy {train_acc}')\n    print(f'Val loss {val_loss} accuracy {val_acc}')\n    print(\"Done!\")","metadata":{"id":"9-bp8ob13hw_","execution":{"iopub.status.busy":"2023-05-17T01:53:42.265619Z","iopub.execute_input":"2023-05-17T01:53:42.265984Z","iopub.status.idle":"2023-05-17T02:05:27.864386Z","shell.execute_reply.started":"2023-05-17T01:53:42.265954Z","shell.execute_reply":"2023-05-17T02:05:27.863350Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Epoch 1\n-------------------------------\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train loss 1.2233306335542866 accuracy 0.45773234667001134\nVal loss 1.2585526950775632 accuracy 0.4420471650777722\nDone!\nEpoch 2\n-------------------------------\nTrain loss 1.1402529874641096 accuracy 0.4966762824532799\nVal loss 1.1548326384453547 accuracy 0.4862017059708981\nDone!\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Prediction with Test Set","metadata":{}},{"cell_type":"code","source":"# prediction with test set\nimport torch.nn.functional as F\n\ndef get_predictions(model, data_loader):\n  model = model.eval()\n  \n  story_texts = []\n  predictions = []\n  real_values = []\n\n  with torch.no_grad():\n    for d in data_loader:\n\n      texts = d[\"review\"]\n      input_ids = d[\"input_ids\"].to(device)\n      attention_mask = d[\"attention_mask\"].to(device)\n      targets = d[\"label\"].to(device)\n\n      outputs = model(\n        input_ids=input_ids,\n        attention_mask=attention_mask\n      )\n      _, preds = torch.max(outputs, dim=1)\n\n      predictions.extend(preds)\n      real_values.extend(targets)\n\n  predictions = torch.stack(predictions).cpu()\n  real_values = torch.stack(real_values).cpu()\n  return predictions, real_values","metadata":{"id":"Hm6I1iVPjIe6","execution":{"iopub.status.busy":"2023-05-17T02:05:27.866726Z","iopub.execute_input":"2023-05-17T02:05:27.867363Z","iopub.status.idle":"2023-05-17T02:05:27.877078Z","shell.execute_reply.started":"2023-05-17T02:05:27.867293Z","shell.execute_reply":"2023-05-17T02:05:27.876162Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\ny_pred, y_test = get_predictions(model, test_dataloader)\n\nprint(classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2023-05-17T02:05:27.878502Z","iopub.execute_input":"2023-05-17T02:05:27.878836Z","iopub.status.idle":"2023-05-17T02:06:04.345832Z","shell.execute_reply.started":"2023-05-17T02:05:27.878805Z","shell.execute_reply":"2023-05-17T02:06:04.344587Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.59      0.42      0.49       247\n           1       0.30      0.25      0.27       225\n           2       0.42      0.74      0.53       507\n           3       0.47      0.29      0.36       507\n           4       0.71      0.58      0.64       508\n\n    accuracy                           0.49      1994\n   macro avg       0.50      0.45      0.46      1994\nweighted avg       0.51      0.49      0.48      1994\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}