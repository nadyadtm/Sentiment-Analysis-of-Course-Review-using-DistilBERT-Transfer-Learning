{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Sentiment Analysis in Course Review using DistilBERT Transfer Learning\n\n## Background\nDalam perusahaan edukasi, feedback siswa merupakan komponen penting dalam meningkatkan kualitas pembelajaran. Biasanya, feedback tersebut dalam bentuk tulisan atau teks. Feedback teks mengandung berbagai macam insight sehingga dapat dieksplorasi lebih lanjut.\n\nDalam data bentuk teks, kita dapat menemukan sentimen dari teks tersebut, yaitu mengetahui apakah feedback tersebut bersifat positif, netral, atau negatif. Namun, bila jumlah feedback besar akan sangat sulit untuk mengecek satu-satu sentimennya. Oleh karena itu perlu proses yang otomatis untuk mendapatkan sentimen dari teks tersebut, yaitu dengan menggunakan analisis sentimen.","metadata":{"id":"-6ETzS8O1wjN"}},{"cell_type":"markdown","source":"## Install Package","metadata":{"id":"d8E-9Ry1_RIf"}},{"cell_type":"code","source":"# !pip install nlpaug","metadata":{"id":"9vO_aOkO_UKM","execution":{"iopub.status.busy":"2023-05-17T00:18:21.713841Z","iopub.execute_input":"2023-05-17T00:18:21.714709Z","iopub.status.idle":"2023-05-17T00:18:21.722839Z","shell.execute_reply.started":"2023-05-17T00:18:21.714675Z","shell.execute_reply":"2023-05-17T00:18:21.721986Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install transformers","metadata":{"id":"JYu9o-_DEq03","outputId":"9a91f33d-6b75-4f69-ba4c-afb226128183","execution":{"iopub.status.busy":"2023-05-17T00:18:21.726184Z","iopub.execute_input":"2023-05-17T00:18:21.727007Z","iopub.status.idle":"2023-05-17T00:18:35.801471Z","shell.execute_reply.started":"2023-05-17T00:18:21.726958Z","shell.execute_reply":"2023-05-17T00:18:35.800169Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.28.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.11.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.28.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\nRequirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.4)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.64.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.3.23)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.1.1)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2022.12.7)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"## Set Device","metadata":{"id":"0DhkBxRhGEbS"}},{"cell_type":"code","source":"#mengecek apakah terdapat GPU pada komputer\nimport torch\nif torch.cuda.is_available():       \n    device = torch.device(\"cuda\")\n    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n    print('Device name:', torch.cuda.get_device_name(0))\n#jika tidak ada maka gunakan CPU untuk menjalankan program\nelse:\n    print('No GPU available, using the CPU instead.')\n    device = torch.device(\"cpu\")","metadata":{"id":"5FBnzkWXGGZh","outputId":"25e9734f-05e8-41ad-ee8d-c44af01efadd","execution":{"iopub.status.busy":"2023-05-17T00:18:35.804334Z","iopub.execute_input":"2023-05-17T00:18:35.805036Z","iopub.status.idle":"2023-05-17T00:18:39.353585Z","shell.execute_reply.started":"2023-05-17T00:18:35.804989Z","shell.execute_reply":"2023-05-17T00:18:39.352558Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"There are 2 GPU(s) available.\nDevice name: Tesla T4\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Import Packages","metadata":{"id":"Jcvi2xO61wjc"}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom os import path\nfrom PIL import Image\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nimport torch\nimport transformers\nfrom transformers import DistilBertModel, DistilBertTokenizer\nfrom torch.optim import AdamW\n\nimport os\nimport nltk\nnltk.download(\"punkt\")\n\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)\ntorch.manual_seed(RANDOM_SEED)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","id":"-G9LOlgv1wje","outputId":"17a123a8-aad8-4900-f7ac-4523a458a0df","execution":{"iopub.status.busy":"2023-05-17T00:18:39.360379Z","iopub.execute_input":"2023-05-17T00:18:39.361316Z","iopub.status.idle":"2023-05-17T00:18:50.977598Z","shell.execute_reply.started":"2023-05-17T00:18:39.361289Z","shell.execute_reply":"2023-05-17T00:18:50.976644Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7fc8d8d67d50>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Load Dataset\nDalam notebook ini, akan digunakan dataset 100k Courseras Course Review, yang telah discrapping dari website coursera.","metadata":{"id":"dNCbpA871wjm"}},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/100k-courseras-course-reviews-dataset/reviews.csv\")\ndf.head()","metadata":{"id":"1u1rs9QC1wjn","outputId":"153c1c37-ed1e-4cde-9bc2-1cf10baaff5f","execution":{"iopub.status.busy":"2023-05-17T00:18:50.979214Z","iopub.execute_input":"2023-05-17T00:18:50.979928Z","iopub.status.idle":"2023-05-17T00:18:51.442634Z","shell.execute_reply.started":"2023-05-17T00:18:50.979894Z","shell.execute_reply":"2023-05-17T00:18:51.441340Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"   Id                                             Review  Label\n0   0                               good and interesting      5\n1   1  This class is very helpful to me. Currently, I...      5\n2   2  like!Prof and TAs are helpful and the discussi...      5\n3   3  Easy to follow and includes a lot basic and im...      5\n4   4  Really nice teacher!I could got the point eazl...      4","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>Review</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>good and interesting</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>This class is very helpful to me. Currently, I...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>like!Prof and TAs are helpful and the discussi...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Easy to follow and includes a lot basic and im...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Really nice teacher!I could got the point eazl...</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# convert label\ndf['Label'] = df['Label'].astype(\"category\")\ndf['Label'] = df['Label'].cat.rename_categories(\n    {\n        5 : 4, 4 : 3, 3 : 2, 2: 1, 1: 0\n    }\n)","metadata":{"id":"dd6E4UtzQeA1","execution":{"iopub.status.busy":"2023-05-17T00:18:51.444173Z","iopub.execute_input":"2023-05-17T00:18:51.445247Z","iopub.status.idle":"2023-05-17T00:18:51.460180Z","shell.execute_reply.started":"2023-05-17T00:18:51.445210Z","shell.execute_reply":"2023-05-17T00:18:51.459271Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"id":"_jM3yUAbQ4kn","outputId":"47f03b27-8cbf-4c3e-e582-f34a18f97234","execution":{"iopub.status.busy":"2023-05-17T00:18:51.461787Z","iopub.execute_input":"2023-05-17T00:18:51.462178Z","iopub.status.idle":"2023-05-17T00:18:51.476200Z","shell.execute_reply.started":"2023-05-17T00:18:51.462143Z","shell.execute_reply":"2023-05-17T00:18:51.475226Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"   Id                                             Review Label\n0   0                               good and interesting     4\n1   1  This class is very helpful to me. Currently, I...     4\n2   2  like!Prof and TAs are helpful and the discussi...     4\n3   3  Easy to follow and includes a lot basic and im...     4\n4   4  Really nice teacher!I could got the point eazl...     3","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>Review</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>good and interesting</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>This class is very helpful to me. Currently, I...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>like!Prof and TAs are helpful and the discussi...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Easy to follow and includes a lot basic and im...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Really nice teacher!I could got the point eazl...</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Text Analysis (EDA)\nPada bagian ini, akan dilakukan EDA (Exploratory Data Analysis) untuk mendapatkan insight dari dataset tersebut.","metadata":{"id":"bzGhqtj81wjp"}},{"cell_type":"markdown","source":"### Class Distribution\nPada bagian ini, akan dilakukan pengecekan distribusi kelas dengan menghitung jumlah kalimat yang termasuk kelas tersebut","metadata":{"id":"TitMwOi11wjq"}},{"cell_type":"code","source":"# check class distribution\nimport seaborn as sns\ndf[\"Label\"].value_counts()","metadata":{"id":"XJKg6FSn1wjs","outputId":"56fde5fb-d8f7-4aad-df5a-e12d97459883","execution":{"iopub.status.busy":"2023-05-17T00:18:51.477576Z","iopub.execute_input":"2023-05-17T00:18:51.478129Z","iopub.status.idle":"2023-05-17T00:18:51.490989Z","shell.execute_reply.started":"2023-05-17T00:18:51.478098Z","shell.execute_reply":"2023-05-17T00:18:51.489950Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"4    79173\n3    18054\n2     5071\n0     2469\n1     2251\nName: Label, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"### Checking Sentence Length\nPada bagian ini, akan dilakukan pengecekan panjang kalimat dengan menghitung jumlah kata per kalimat.","metadata":{"id":"4ho6TpFx1wju"}},{"cell_type":"code","source":"# check len sentence\nfrom nltk.tokenize import word_tokenize\n\ndf['length_sen'] = df['Review'].apply(lambda x : len(word_tokenize(x)))","metadata":{"id":"LFTqwtur1wjy","execution":{"iopub.status.busy":"2023-05-17T00:18:51.492437Z","iopub.execute_input":"2023-05-17T00:18:51.492834Z","iopub.status.idle":"2023-05-17T00:19:33.122199Z","shell.execute_reply.started":"2023-05-17T00:18:51.492797Z","shell.execute_reply":"2023-05-17T00:19:33.121248Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"id":"L1hCEPiE1wj0","outputId":"29f8da39-e266-458f-96a0-ff50d67b710c","execution":{"iopub.status.busy":"2023-05-17T00:19:33.127314Z","iopub.execute_input":"2023-05-17T00:19:33.127597Z","iopub.status.idle":"2023-05-17T00:19:33.137583Z","shell.execute_reply.started":"2023-05-17T00:19:33.127573Z","shell.execute_reply":"2023-05-17T00:19:33.136568Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"   Id                                             Review Label  length_sen\n0   0                               good and interesting     4           3\n1   1  This class is very helpful to me. Currently, I...     4          26\n2   2  like!Prof and TAs are helpful and the discussi...     4          21\n3   3  Easy to follow and includes a lot basic and im...     4          15\n4   4  Really nice teacher!I could got the point eazl...     3          13","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>Review</th>\n      <th>Label</th>\n      <th>length_sen</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>good and interesting</td>\n      <td>4</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>This class is very helpful to me. Currently, I...</td>\n      <td>4</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>like!Prof and TAs are helpful and the discussi...</td>\n      <td>4</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Easy to follow and includes a lot basic and im...</td>\n      <td>4</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Really nice teacher!I could got the point eazl...</td>\n      <td>3</td>\n      <td>13</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Berikut ini adalah maksimal panjang kalimat dari dataset tersebut.","metadata":{"id":"MQz9GOVZ1wj0"}},{"cell_type":"code","source":"# max length\nmax_len = max(df['length_sen'])\nprint(\"Max Length : \", max(df['length_sen']))","metadata":{"id":"76F7uKta1wj3","outputId":"932d0147-aee6-41eb-dc74-ee9ff7279e8f","execution":{"iopub.status.busy":"2023-05-17T00:19:33.138842Z","iopub.execute_input":"2023-05-17T00:19:33.139526Z","iopub.status.idle":"2023-05-17T00:19:33.176118Z","shell.execute_reply.started":"2023-05-17T00:19:33.139493Z","shell.execute_reply":"2023-05-17T00:19:33.174831Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Max Length :  1461\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Text Preprocessing","metadata":{"id":"lSkEHuOM1wj4"}},{"cell_type":"code","source":"# Lowercase\ndf['Review'] = df['Review'].apply(lambda x : str.lower(x))","metadata":{"id":"iKavCi4W1wj4","execution":{"iopub.status.busy":"2023-05-17T00:19:33.177531Z","iopub.execute_input":"2023-05-17T00:19:33.177931Z","iopub.status.idle":"2023-05-17T00:19:33.246083Z","shell.execute_reply.started":"2023-05-17T00:19:33.177899Z","shell.execute_reply":"2023-05-17T00:19:33.244907Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"### Data Splitting","metadata":{"id":"-7LPCo_F1wj9"}},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(df[\"Review\"], df[\"Label\"], test_size=0.2, random_state=42, stratify = df[\"Label\"])\nX_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42, stratify = y_test)","metadata":{"id":"BRH1THCv1wj9","execution":{"iopub.status.busy":"2023-05-17T00:19:33.247476Z","iopub.execute_input":"2023-05-17T00:19:33.248299Z","iopub.status.idle":"2023-05-17T00:19:33.317194Z","shell.execute_reply.started":"2023-05-17T00:19:33.248250Z","shell.execute_reply":"2023-05-17T00:19:33.316211Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"print(X_train.shape)\nprint(X_test.shape)\nprint(X_val.shape)","metadata":{"id":"5y5KBMQ1Ccfd","outputId":"fb838a4f-f2d6-4ce3-b159-aa1dfbfb76aa","execution":{"iopub.status.busy":"2023-05-17T00:19:33.318718Z","iopub.execute_input":"2023-05-17T00:19:33.319076Z","iopub.status.idle":"2023-05-17T00:19:33.324960Z","shell.execute_reply.started":"2023-05-17T00:19:33.319042Z","shell.execute_reply":"2023-05-17T00:19:33.323664Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"(85614,)\n(10702,)\n(10702,)\n","output_type":"stream"}]},{"cell_type":"code","source":"y_train.value_counts()","metadata":{"id":"t_knlgPGCiYN","outputId":"089e9250-f61d-4702-eaef-b4f4551793e9","execution":{"iopub.status.busy":"2023-05-17T00:19:33.326755Z","iopub.execute_input":"2023-05-17T00:19:33.327198Z","iopub.status.idle":"2023-05-17T00:19:33.339767Z","shell.execute_reply.started":"2023-05-17T00:19:33.327156Z","shell.execute_reply":"2023-05-17T00:19:33.338854Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"4    63338\n3    14443\n2     4057\n0     1975\n1     1801\nName: Label, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"y_test.value_counts()","metadata":{"id":"ag_vy_KdCnni","outputId":"375a83e9-d774-4aee-dac6-07b8bce4e80e","execution":{"iopub.status.busy":"2023-05-17T00:19:33.341178Z","iopub.execute_input":"2023-05-17T00:19:33.342152Z","iopub.status.idle":"2023-05-17T00:19:33.352051Z","shell.execute_reply.started":"2023-05-17T00:19:33.342120Z","shell.execute_reply":"2023-05-17T00:19:33.351131Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"4    7917\n3    1806\n2     507\n0     247\n1     225\nName: Label, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"y_val.value_counts()","metadata":{"id":"f-mWy4_iq_PU","outputId":"10b82713-a8f0-4cc4-f1f2-5fa9912706cf","execution":{"iopub.status.busy":"2023-05-17T00:19:33.353451Z","iopub.execute_input":"2023-05-17T00:19:33.354165Z","iopub.status.idle":"2023-05-17T00:19:33.366429Z","shell.execute_reply.started":"2023-05-17T00:19:33.354132Z","shell.execute_reply":"2023-05-17T00:19:33.365345Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"4    7918\n3    1805\n2     507\n0     247\n1     225\nName: Label, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"## Build BERT Model\n\n- Tambah penjelasan bert model --> dibaliknya apa, basic algoritma\n- penjelasan framework pytorch","metadata":{"id":"BgfXOVv3CXET"}},{"cell_type":"code","source":"#import bert tokenizer, pilih yang multilingual karena lebih dari 1 bahasa\n\ntokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-cased')\nmodel = DistilBertModel.from_pretrained('distilbert-base-cased')","metadata":{"id":"0DaRUDivCZIE","outputId":"92283809-5af4-4747-ad1e-3dc9fdd594fd","execution":{"iopub.status.busy":"2023-05-17T00:19:33.367895Z","iopub.execute_input":"2023-05-17T00:19:33.368448Z","iopub.status.idle":"2023-05-17T00:19:37.166582Z","shell.execute_reply.started":"2023-05-17T00:19:33.368416Z","shell.execute_reply":"2023-05-17T00:19:37.165519Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5adc8cb52984d4087f74379b8ffd517"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50f2dd8dcde74a60a14297635c76883f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/411 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ee61a18606d4f9c9b76b7c06aa0e57e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/263M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f193844747da454d968f84a46e8b0c52"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.weight']\n- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### BERT Data Loader","metadata":{"id":"sbTPjLDvPjd1"}},{"cell_type":"code","source":"#fungsi untuk loading dataset\nfrom torch.utils.data import Dataset\n\nclass ReviewDataset(Dataset):\n  def __init__(self, reviews, labels, max_len, tokenizer):\n    self.reviews = reviews.reset_index()[\"Review\"]\n    self.labels = labels.reset_index()[\"Label\"]\n    self.max_len = max_len\n    self.tokenizer = tokenizer\n\n  def __len__(self):\n    return len(self.labels)\n  \n  def __getitem__(self, idx):\n    reviews = self.reviews[idx]\n    labels = self.labels[idx]\n\n    encoding = self.tokenizer.encode_plus(\n      reviews,                      \n      add_special_tokens=True,    \n      max_length=self.max_len,    \n      pad_to_max_length=True,     \n      truncation=True,            \n      return_attention_mask=True, \n      return_tensors='pt'         \n    )\n\n    return {\n        'review': reviews,\n        'input_ids': encoding['input_ids'].flatten(),\n        'attention_mask': encoding['attention_mask'].flatten(),\n        'label': torch.tensor(labels, dtype=torch.long)\n    }","metadata":{"id":"ux7wzfLvPea2","execution":{"iopub.status.busy":"2023-05-17T00:19:37.168162Z","iopub.execute_input":"2023-05-17T00:19:37.168577Z","iopub.status.idle":"2023-05-17T00:19:37.177412Z","shell.execute_reply.started":"2023-05-17T00:19:37.168513Z","shell.execute_reply":"2023-05-17T00:19:37.176049Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"train_data = ReviewDataset(X_train,y_train, 512, tokenizer)\nval_data = ReviewDataset(X_val,y_val, 512, tokenizer)\ntest_data = ReviewDataset(X_test,y_test, 512, tokenizer)","metadata":{"id":"iPYh8-7Cf65e","execution":{"iopub.status.busy":"2023-05-17T00:19:37.178996Z","iopub.execute_input":"2023-05-17T00:19:37.179654Z","iopub.status.idle":"2023-05-17T00:19:37.197391Z","shell.execute_reply.started":"2023-05-17T00:19:37.179622Z","shell.execute_reply":"2023-05-17T00:19:37.196193Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\ntrain_dataloader = DataLoader(train_data, batch_size=32, shuffle=True)\nval_dataloader = DataLoader(val_data, batch_size=32, shuffle=True)\ntest_dataloader = DataLoader(test_data, batch_size=32, shuffle=True)","metadata":{"id":"4HKtUo9Wh5TJ","execution":{"iopub.status.busy":"2023-05-17T00:19:37.198882Z","iopub.execute_input":"2023-05-17T00:19:37.199216Z","iopub.status.idle":"2023-05-17T00:19:37.205201Z","shell.execute_reply.started":"2023-05-17T00:19:37.199184Z","shell.execute_reply":"2023-05-17T00:19:37.204236Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"### Bert Transfer Learning","metadata":{"id":"gPhfd5ZNqQa3"}},{"cell_type":"code","source":"from torch import nn\nclass Bert_TL(nn.Module):\n  def __init__(self,bert):\n    super(Bert_TL, self).__init__()\n    self.bert = bert\n    self.fc1 = nn.Linear(768,512)\n    self.relu = nn.ReLU()\n    self.fc2 = nn.Linear(512,5)\n  \n  def forward(self, input_ids, attention_mask):\n    hidden = self.bert(input_ids = input_ids, attention_mask = attention_mask)\n    x = self.fc1(hidden[0][:, 0, :])\n    x = self.relu(x)\n    x = self.fc2(x)\n    \n    return x","metadata":{"id":"t3UaEB9wqZdb","execution":{"iopub.status.busy":"2023-05-17T00:19:37.206686Z","iopub.execute_input":"2023-05-17T00:19:37.207841Z","iopub.status.idle":"2023-05-17T00:19:37.216716Z","shell.execute_reply.started":"2023-05-17T00:19:37.207809Z","shell.execute_reply":"2023-05-17T00:19:37.215593Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"model = Bert_TL(model)\nmodel.to(torch.device(\"cuda\"))","metadata":{"id":"NMADSNPZq7s2","outputId":"05765314-5d78-4b8b-eb6f-8d4090505c69","execution":{"iopub.status.busy":"2023-05-17T00:19:37.218051Z","iopub.execute_input":"2023-05-17T00:19:37.218604Z","iopub.status.idle":"2023-05-17T00:19:42.891244Z","shell.execute_reply.started":"2023-05-17T00:19:37.218573Z","shell.execute_reply":"2023-05-17T00:19:42.890290Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"Bert_TL(\n  (bert): DistilBertModel(\n    (embeddings): Embeddings(\n      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (transformer): Transformer(\n      (layer): ModuleList(\n        (0-5): 6 x TransformerBlock(\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n            (activation): GELUActivation()\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n      )\n    )\n  )\n  (fc1): Linear(in_features=768, out_features=512, bias=True)\n  (relu): ReLU()\n  (fc2): Linear(in_features=512, out_features=5, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.utils.class_weight import compute_class_weight\n\n#compute the class weights\nclass_weights = compute_class_weight(class_weight = 'balanced', \n                                     classes = np.unique(y_train), \n                                     y = y_train)\n\nclass_weights_t = torch.tensor(class_weights, dtype=torch.float)\n\nclass_weights_t = class_weights_t.to(device)\n\nprint(\"Class Weights:\",class_weights)\nprint(np.unique(y_train))","metadata":{"id":"Rz2jJgtV3K87","execution":{"iopub.status.busy":"2023-05-17T00:19:42.892805Z","iopub.execute_input":"2023-05-17T00:19:42.893137Z","iopub.status.idle":"2023-05-17T00:19:42.916096Z","shell.execute_reply.started":"2023-05-17T00:19:42.893107Z","shell.execute_reply":"2023-05-17T00:19:42.915191Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Class Weights: [8.66977215 9.50738479 4.22055706 1.18554317 0.27034008]\n[0 1 2 3 4]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Inisiasi hyperparameter\nlearning_rate = 1e-3\n\n#inisiasi loss function\nloss_fn =nn.CrossEntropyLoss(weight=class_weights_t).to(device)\noptimizer = AdamW(model.parameters(), lr=learning_rate)\n\nfor param in model.bert.parameters():\n    param.requires_grad = False","metadata":{"id":"3dO0UEzmD5du","execution":{"iopub.status.busy":"2023-05-17T00:19:42.917603Z","iopub.execute_input":"2023-05-17T00:19:42.918523Z","iopub.status.idle":"2023-05-17T00:19:42.926614Z","shell.execute_reply.started":"2023-05-17T00:19:42.918490Z","shell.execute_reply":"2023-05-17T00:19:42.925471Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"def train_loop(\n  data_loader, \n  model, \n  loss_fn, \n  optimizer, \n  device, \n  n_examples\n):\n  #menandakan bahwa model sedang dilatih\n  model = model.train()\n\n  losses = []\n  correct_predictions = 0\n  \n  #iterasi di setiap data\n  for d in data_loader:\n\n    #mengambil input id, attention mask, dan target dari setiap data\n    input_ids = d[\"input_ids\"].to(device)\n    attention_mask = d[\"attention_mask\"].to(device)\n    targets = d[\"label\"].to(device)\n\n    #mengeluarkan output dari data tersebut\n    outputs = model(\n      input_ids=input_ids,\n      attention_mask=attention_mask\n    )\n\n    #mengeluarkan prediksi target\n    _, preds = torch.max(outputs, dim=1)\n\n    #mengeluarkan lossnya\n    loss = loss_fn(outputs, targets)\n\n    #menjumlahkan prediksi target yang benar\n    correct_predictions += torch.sum(preds == targets)\n\n    #mengumpulkan loss dari output dan target\n    losses.append(loss.item())\n\n    loss.backward()\n\n    #untuk menghindari vanishing gradient\n    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n    optimizer.step()\n    optimizer.zero_grad()\n\n  #mengembalikan akurasi dan rata-rata loss\n  return correct_predictions.double() / n_examples, np.mean(losses)\n\n\ndef test_loop(model, data_loader, loss_fn, device, n_examples):\n\n  #menandakan model sedang dievaluasi\n  model = model.eval()\n\n  #array losses dari setiap data dan variabel correct_prediction untuk jumlah prediksi benar\n  losses = []\n  correct_predictions = 0\n\n  with torch.no_grad():\n    for d in data_loader:\n      #mengambil input id, attention mask, dan target dari setiap data\n      input_ids = d[\"input_ids\"].to(device)\n      attention_mask = d[\"attention_mask\"].to(device)\n      targets = d[\"label\"].to(device)\n\n      #mengambil output dari data\n      outputs = model(\n        input_ids=input_ids,\n        attention_mask=attention_mask\n      )\n\n      #mengambil kelas prediksi\n      _, preds = torch.max(outputs, dim=1)\n      \n      #mengeluarkan loss dari output dan targets\n      loss = loss_fn(outputs, targets)\n\n      #menjumlahkan prediksi yang benar\n      correct_predictions += torch.sum(preds == targets)\n      losses.append(loss.item())\n\n  #mengembalikan akurasi dan rata-rata loss\n  return correct_predictions.double() / n_examples, np.mean(losses)","metadata":{"id":"nLDUnQI81ADw","execution":{"iopub.status.busy":"2023-05-17T00:19:42.928661Z","iopub.execute_input":"2023-05-17T00:19:42.928989Z","iopub.status.idle":"2023-05-17T00:19:42.942829Z","shell.execute_reply.started":"2023-05-17T00:19:42.928960Z","shell.execute_reply":"2023-05-17T00:19:42.941944Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# loss_fn = nn.CrossEntropyLoss()\n# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n\nepochs = 2\nfor t in range(epochs):\n    print(f\"Epoch {t+1}\\n-------------------------------\")\n    train_acc, train_loss = train_loop(train_dataloader, model, loss_fn, optimizer,device,len(X_train))\n    #memanggil fungsi eval model\n    val_acc, val_loss = test_loop(\n      model,\n      val_dataloader,\n      loss_fn, \n      device, \n      len(X_val)\n    )\n\n    #mencetak val loss dan accuracy\n    print(f'Train loss {train_loss} accuracy {train_acc}')\n    print(f'Val loss {val_loss} accuracy {val_acc}')\n    print(\"Done!\")","metadata":{"id":"9-bp8ob13hw_","execution":{"iopub.status.busy":"2023-05-17T00:19:42.944428Z","iopub.execute_input":"2023-05-17T00:19:42.945072Z","iopub.status.idle":"2023-05-17T01:20:43.692916Z","shell.execute_reply.started":"2023-05-17T00:19:42.945040Z","shell.execute_reply":"2023-05-17T01:20:43.691182Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Epoch 1\n-------------------------------\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train loss 1.2303594723789324 accuracy 0.6182867288060364\nVal loss 1.160517922977903 accuracy 0.6810876471687535\nDone!\nEpoch 2\n-------------------------------\nTrain loss 1.1725525234802243 accuracy 0.6434228046814774\nVal loss 1.1602736528240034 accuracy 0.5584002990095309\nDone!\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Prediction with Test Set","metadata":{}},{"cell_type":"code","source":"# prediction with test set\nimport torch.nn.functional as F\n\ndef get_predictions(model, data_loader):\n  model = model.eval()\n  \n  story_texts = []\n  predictions = []\n  real_values = []\n\n  with torch.no_grad():\n    for d in data_loader:\n\n      texts = d[\"review\"]\n      input_ids = d[\"input_ids\"].to(device)\n      attention_mask = d[\"attention_mask\"].to(device)\n      targets = d[\"label\"].to(device)\n\n      outputs = model(\n        input_ids=input_ids,\n        attention_mask=attention_mask\n      )\n      _, preds = torch.max(outputs, dim=1)\n\n      predictions.extend(preds)\n      real_values.extend(targets)\n\n  predictions = torch.stack(predictions).cpu()\n  real_values = torch.stack(real_values).cpu()\n  return predictions, real_values","metadata":{"id":"Hm6I1iVPjIe6","execution":{"iopub.status.busy":"2023-05-17T01:35:52.681202Z","iopub.execute_input":"2023-05-17T01:35:52.681666Z","iopub.status.idle":"2023-05-17T01:35:52.690878Z","shell.execute_reply.started":"2023-05-17T01:35:52.681633Z","shell.execute_reply":"2023-05-17T01:35:52.689720Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\ny_pred, y_test = get_predictions(model, test_dataloader)\n\nprint(classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2023-05-17T01:40:24.028965Z","iopub.execute_input":"2023-05-17T01:40:24.029347Z","iopub.status.idle":"2023-05-17T01:43:34.493630Z","shell.execute_reply.started":"2023-05-17T01:40:24.029316Z","shell.execute_reply":"2023-05-17T01:43:34.492465Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.51      0.32      0.39       247\n           1       0.27      0.31      0.29       225\n           2       0.24      0.55      0.34       507\n           3       0.22      0.51      0.31      1806\n           4       0.92      0.58      0.71      7917\n\n    accuracy                           0.56     10702\n   macro avg       0.43      0.45      0.41     10702\nweighted avg       0.75      0.56      0.61     10702\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}